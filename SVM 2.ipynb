{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c42a6d8-83f5-4ac3-bdb7-67f4165c8424",
   "metadata": {},
   "source": [
    "# Q1. \n",
    "Polynomial functions and kernel functions are closely related in machine learning algorithms, particularly in Support Vector Machines (SVMs). A polynomial kernel function is a type of kernel function used in SVMs to handle non-linear decision boundaries by mapping input features into a higher-dimensional space. This mapping allows SVMs to find linear decision boundaries in the transformed space, effectively capturing non-linear relationships between features. Polynomial functions, on the other hand, are mathematical functions that can be used as basis functions for polynomial kernel functions. In essence, polynomial kernel functions utilize polynomial functions to transform the input features into a higher-dimensional space, enabling SVMs to perform non-linear class\n",
    "ification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929b230-1623-4409-abfc-e4f1d3cefddf",
   "metadata": {},
   "source": [
    "# Q2. To implement an SVM with a polynomial kernel in Python using Scikit-learn, you can use the SVC class with the kernel='poly' parameter. Here's an example code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2ef325-a9ae-4243-b956-173607f9ebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (e.g., scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier with polynomial kernel\n",
    "svc_poly = SVC(kernel='poly', degree=3)  # Use degree parameter to specify polynomial degree\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svc_poly.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained classifier to predict labels of the testing data\n",
    "y_pred = svc_poly.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59503a1-91c8-4867-a317-556a0cb40c39",
   "metadata": {},
   "source": [
    "# Q3. \n",
    "Increasing the value of epsilon in Support Vector Regression (SVR) typically results in fewer support vectors. \n",
    "Epsilon controls the width of the epsilon-tube around the regression line within which no penalty is associated with errors. \n",
    "As epsilon increases, the margin around the regression line widens, allowing more data points to fall within the margin without incurring a penalty. \n",
    "Consequently, fewer support vectors are needed to define the regression line, as the tolerance for errors increases.\n",
    "\n",
    "# Q4. \n",
    "In Support Vector Regression (SVR), the choice of kernel function, C parameter, epsilon parameter, and gamma parameter can significantly affect the performance of the model:\n",
    "\n",
    "Kernel Function: Different kernel functions (e.g., linear, polynomial, radial basis function) can capture different types of relationships in the data. \n",
    "\n",
    "The choice of kernel function should be based on the underlying data distribution and the complexity of the problem.\n",
    "\n",
    "C Parameter: The C parameter controls the trade-off between maximizing the margin and minimizing the error. \n",
    "\n",
    "Higher values of C result in a smaller margin and may lead to overfitting, while lower values of C result in a larger margin and may lead to underfitting. It is essential to tune the C parameter to find the right balance between bias and variance.\n",
    "\n",
    "Epsilon Parameter: The epsilon parameter determines the width of the epsilon-tube around the regression line. Larger values of epsilon allow for more errors within the tube, while smaller values enforce a tighter fit to the training data. Tuning epsilon is crucial for controlling the trade-off between model flexibility and generalization.\n",
    "\n",
    "\n",
    "Gamma Parameter: The gamma parameter defines the influence of individual training samples on the model. Higher values of gamma lead to more complex decision boundaries and can result in overfitting, especially with non-linear kernel functions like radial basis function (RBF). Lower values of gamma result in smoother decision boundaries and may improve generalization performance.\n",
    "\n",
    "Example: If the dataset is highly non-linear, it may be beneficial to use a non-linear kernel function like RBF and tune the gamma parameter to control the smoothness of the decision boundaries. Additionally, adjusting the C parameter can help balance the model's bias and variance, while tuning the epsilon parameter can regulate the tolerance for errors in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c44cf5-8b2a-422e-9779-7fce4e1cdbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_classifier.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (e.g., scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'gamma': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the best estimator from GridSearchCV to predict labels of the testing data\n",
    "best_svc = grid_search.best_estimator_\n",
    "y_pred = best_svc.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Save the trained classifier to a file\n",
    "joblib.dump(best_svc, 'svm_classifier.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
