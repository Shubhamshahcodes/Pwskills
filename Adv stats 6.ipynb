{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2083fadd-f0ef-4838-9fe5-8461b83288fe",
   "metadata": {},
   "source": [
    "# Q1. Assumptions of ANOVA include:\n",
    "\n",
    "Independence: Observations in each group are independent of each other.\n",
    "\n",
    "Normality: The residuals (errors) from the model are normally distributed.\n",
    "\n",
    "Homogeneity of variances: The variance of the residuals is constant across all groups.\n",
    "\n",
    "Violations of these assumptions can impact the validity of ANOVA results. For example, if the assumption of homogeneity of variances is violated, meaning that the variance of the residuals is not constant across groups, then the F-test may become unreliable, leading to incorrect conclusions about group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2de4a3-aed6-40cf-a1d6-60e1c2063bbd",
   "metadata": {},
   "source": [
    "# Q2. The three types of ANOVA are:\n",
    "\n",
    "One-way ANOVA: Used when comparing the means of three or more independent groups.\n",
    "\n",
    "Two-way ANOVA: Used when there are two independent variables or factors, each with multiple levels, and we want to study their main effects and interaction effects.\n",
    "\n",
    "Repeated measures ANOVA: Used when the same subjects are measured at multiple time points or under multiple conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090661d-6f9e-4b9a-b334-3eece69a45b3",
   "metadata": {},
   "source": [
    "# Q3. \n",
    "The partitioning of variance in ANOVA involves dividing the total variation observed in the data into different components attributed to various sources, such as group differences, error, and interaction effects. Understanding this concept is important because it helps us quantify the relative contribution of different factors to the overall variation in the data and interpret the significance of these factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172db90-2859-47c6-8859-0c016d01c14f",
   "metadata": {},
   "source": [
    "# Q4. \n",
    "To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can use the following formulas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9adc8bce-d25b-4835-b0fd-7b0e83d9d110",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m SST \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((\u001b[43mdata\u001b[49m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(data))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m SSE \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((group_means \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(data))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m SSR \u001b[38;5;241m=\u001b[39m SST \u001b[38;5;241m-\u001b[39m SSE\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "SST = np.sum((data - np.mean(data))**2)\n",
    "SSE = np.sum((group_means - np.mean(data))**2)\n",
    "SSR = SST - SSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538b4ac-d6d8-4261-ab70-792ba76ce463",
   "metadata": {},
   "source": [
    "# Q5. \n",
    "In a two-way ANOVA, you can calculate the main effects by comparing the means of each level of one factor while holding the other factor constant.\n",
    "\n",
    "Interaction effects can be calculated by comparing the differences in means between different combinations of factor levels. \n",
    "\n",
    "You can use Python's statistical libraries like scipy or statsmodels to perform these calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0716cd-365c-43a5-8005-bbd5d6ba97e0",
   "metadata": {},
   "source": [
    "# Q6. \n",
    "In the given scenario, with an F-statistic of 5.23 and a p-value of 0.02, we would reject the null hypothesis and conclude that there are significant differences between the groups. \n",
    "The p-value indicates that there is less than a 2% probability of observing such extreme differences between groups if the null hypothesis (no group differences) were true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f3251-5ddd-46f1-a24a-c05550ff8309",
   "metadata": {},
   "source": [
    "# Q7. \n",
    "\n",
    "To handle missing data in repeated measures ANOVA, various methods can be used such as mean imputation, last observation carried forward (LOCF), or multiple imputation. \n",
    "The consequences of using different methods include potential biases in the estimated treatment effects and standard errors, which can affect the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70071ad3-e8b6-4ab3-b7df-cdd677a5713d",
   "metadata": {},
   "source": [
    "# Q8. \n",
    "Common post-hoc tests used after ANOVA include Tukey's HSD (Honestly Significant Difference), Bonferroni correction, and Scheffe's method. These tests are used to identify which specific groups differ significantly from each other after finding a significant result in the ANOVA. \n",
    "\n",
    "For example, Tukey's HSD test is often used when the number of pairwise comparisons is large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7893ae-0fd9-44a9-b202-01941e7571d3",
   "metadata": {},
   "source": [
    "# Q9. \n",
    "To conduct a one-way ANOVA in Python to compare the mean weight loss of three diets (A, B, and C), you can use libraries like scipy or statsmodels. \n",
    "\n",
    "After fitting the model, you can obtain the F-statistic and p-value to determine if there are any significant differences between the mean weight loss of the three diets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f0a7d5-c19f-4ae2-90f2-5e1acb11ae5f",
   "metadata": {},
   "source": [
    "# Q10. \n",
    "To conduct a two-way ANOVA in Python to analyze the effects of software programs and employee experience level on task completion time, you can use libraries like statsmodels. \n",
    "\n",
    "After fitting the model, you can obtain the F-statistics and p-values for main effects and interaction effects to determine their significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b06c7-0141-4c98-8ae4-1275f4dc83a9",
   "metadata": {},
   "source": [
    "# Q11. \n",
    "To conduct a two-sample t-test in Python to compare test scores between the control group (traditional teaching method) and the experimental group (new teaching method), you can use libraries like scipy. \n",
    "\n",
    "If the results are significant, you can follow up with a post-hoc test, such as Tukey's HSD, to identify which group(s) differ significantly from each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
